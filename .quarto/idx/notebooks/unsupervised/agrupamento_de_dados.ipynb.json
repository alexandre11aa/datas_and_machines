{"title":"Agrupamento de dados","markdown":{"yaml":{"title":"Agrupamento de dados"},"headingText":"Configuração de dados","containsRefs":false,"markdown":"\n\n\n\n\nO agrupamento de dados, conhecido como clustering em inglês, é uma técnica de análise de dados utilizada para agrupar um conjunto de objetos de forma que objetos no mesmo grupo (ou cluster) sejam mais semelhantes entre si do que com objetos de outros grupos. O objetivo principal é segmentar os dados em grupos significativos e interpretáveis, sem a necessidade de rótulos prévios para os grupos. O clustering é amplamente utilizado em diversas áreas, como mineração de dados, aprendizado de máquina, reconhecimento de padrões, entre outros, para identificar padrões e estruturas nos dados não rotulados.\n\n\n\n\n## Agrupamento K-Means\n\nUsado para agrupar dados não rotulados em clusters com base em suas características. O K-Means visa encontrar grupos nos dados, com um número de grupos (ou clusters) especificado. Sua utilidade está em explorar padrões em conjuntos de dados. \n\nO funcionamento básico do algoritmo K-Means é o seguinte:\n\n1. Inicializa os centróides dos clusters de forma aleatória.\n2. Atribui cada ponto de dados ao centróide mais próximo, formando clusters.\n3. Calcula os novos centróides de cada cluster, com base nos pontos atribuídos a eles.\n4. Repete os passos 2 e 3 até que os centróides não mudem significativamente ou até que um número máximo de iterações seja atingido.\n\n## Agrupamento Expectation-Maximization\n\nO Expectation-Maximization (EM) é usado para modelar dados não rotulados e é especialmente útil quando os dados possuem distribuições ocultas. O objetivo do EM é encontrar os parâmetros de um modelo de mistura de distribuições probabilísticas que melhor descrevem os dados.\n\nO funcionamento básico do algoritmo Expectation-Maximization é o seguinte:\n\n1. Inicializa os parâmetros do modelo de mistura de forma aleatória ou usando alguma heurística.\n2. Passo de Expectation (E-step): Calcula a probabilidade de cada ponto de dados pertencer a cada componente da mistura (responsabilidades).\n3. Passo de Maximization (M-step): Atualiza os parâmetros do modelo para maximizar a probabilidade conjunta dos dados e das 4. responsabilidades calculadas no passo anterior.\n4. Repete os passos 2 e 3 até que os parâmetros converjam ou até que um critério de parada seja atingido.\n\nAlém do spherical, os outros tipos de covariância são:\n\n1. 'tied': Neste caso, todas as componentes do modelo compartilham a mesma matriz de covariância, que é uma matriz completa e simétrica. Isso significa que todas as variáveis têm a mesma covariância entre si.\n\n2. 'diag': Neste caso, cada componente tem sua própria matriz diagonal de covariância, o que significa que as variáveis são consideradas independentes umas das outras, exceto pela sua variância. Ou seja, a covariância entre diferentes dimensões é zero.\n\n3. 'full': Neste caso, cada componente do modelo tem sua própria matriz completa e simétrica de covariância. Isso significa que não há restrições nas covariâncias entre as diferentes variáveis, permitindo correlações arbitrárias entre elas.\n\nEm alguns casos, a escolha deles podem afetar significativamente o agrupamento dos dados.\n\n## Agrupamento Hierarquico Aglomerativo\n\nO Agrupamento Hierárquico Aglomerativo é um algoritmo de agrupamento hierárquico que constrói uma árvore de clusters. Ele começa com cada ponto de dados como um cluster separado e, em seguida, mescla os clusters mais próximos com base em uma métrica de distância até restar apenas um cluster.\n\nA ideia básica do algoritmo é a seguinte:\n\n1. Comece com cada ponto de dados como um cluster separado.\n2. Mescle os dois clusters mais próximos em um único cluster.\n4. Atualize a matriz de distância para refletir as novas distâncias entre clusters.\n5. Repita os passos 2 e 3 até que reste apenas um cluster.\n\nO Agrupamento Hierárquico Aglomerativo é útil para explorar relacionamentos hierárquicos nos dados e pode ser visualizado como um dendrograma, que mostra como os clusters são mesclados em cada etapa.\n\nO parâmetro linkage no algoritmo de Agrupamento Hierárquico Aglomerativo define a estratégia utilizada para calcular a distância entre os clusters durante a mesclagem. Existem diferentes métodos de ligação (linkage) disponíveis:\n\n1. 'complete': Calcula a distância máxima entre os pontos de dois clusters. A distância entre dois clusters é a distância máxima entre seus pontos.\n\n2. 'single': Calcula a distância mínima entre os pontos de dois clusters. A distância entre dois clusters é a distância mínima entre seus pontos.\n\n4. 'average': Calcula a média das distâncias entre os pontos de dois clusters. A distância entre dois clusters é a média das distâncias entre seus pontos.\n\n5. 'ward': Minimiza a variância dos clusters sendo mesclados. Essa abordagem tende a formar clusters de tamanhos relativamente iguais.\n\n## Agrupamento DBSCAN\n\nO DBSCAN (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo de agrupamento baseado em densidade que é capaz de identificar clusters de formatos e tamanhos arbitrários em um conjunto de dados. Ele é especialmente útil quando os clusters têm densidades diferentes, pois ele define clusters como regiões de alta densidade separadas por regiões de baixa densidade.\n\nO funcionamento básico do algoritmo DBSCAN é o seguinte:\n\n1. Cada ponto de dados é classificado como um ponto central, um ponto de borda ou um ponto de ruído.\n2. Para cada ponto central, o algoritmo forma um cluster ao seu redor, incluindo todos os pontos alcançáveis por densidade a partir desse ponto.\n3. Pontos de borda são aqueles que estão dentro da vizinhança de densidade de um ponto central, mas não são pontos centrais eles próprios. Eles são atribuídos ao cluster do ponto central mais próximo em sua vizinhança.\n4. Pontos de ruído são aqueles que não são pontos centrais nem pontos de borda e são descartados ou considerados outliers.\n\nO DBSCAN é útil para encontrar clusters em conjuntos de dados onde os clusters têm diferentes densidades ou quando há presença de ruído nos dados. Ele não requer a especificação do número de clusters a priori, o que o torna uma escolha popular para muitos problemas de agrupamento. Além disso, o DBSCAN é capaz de lidar com clusters de forma arbitrária, não se limitando a formas geométricas específicas.\n\n## Considerações Finais\n\nComo pode ser visto nos gráficos 2D e 3D, após o agrupamento, os dados tendem a se concentrar em volta dos centróides que são dois, visto que correspondem ao número de clusters especificado.\n","srcMarkdownNoYaml":"\n\n\n\n\nO agrupamento de dados, conhecido como clustering em inglês, é uma técnica de análise de dados utilizada para agrupar um conjunto de objetos de forma que objetos no mesmo grupo (ou cluster) sejam mais semelhantes entre si do que com objetos de outros grupos. O objetivo principal é segmentar os dados em grupos significativos e interpretáveis, sem a necessidade de rótulos prévios para os grupos. O clustering é amplamente utilizado em diversas áreas, como mineração de dados, aprendizado de máquina, reconhecimento de padrões, entre outros, para identificar padrões e estruturas nos dados não rotulados.\n\n\n\n### Configuração de dados\n\n## Agrupamento K-Means\n\nUsado para agrupar dados não rotulados em clusters com base em suas características. O K-Means visa encontrar grupos nos dados, com um número de grupos (ou clusters) especificado. Sua utilidade está em explorar padrões em conjuntos de dados. \n\nO funcionamento básico do algoritmo K-Means é o seguinte:\n\n1. Inicializa os centróides dos clusters de forma aleatória.\n2. Atribui cada ponto de dados ao centróide mais próximo, formando clusters.\n3. Calcula os novos centróides de cada cluster, com base nos pontos atribuídos a eles.\n4. Repete os passos 2 e 3 até que os centróides não mudem significativamente ou até que um número máximo de iterações seja atingido.\n\n## Agrupamento Expectation-Maximization\n\nO Expectation-Maximization (EM) é usado para modelar dados não rotulados e é especialmente útil quando os dados possuem distribuições ocultas. O objetivo do EM é encontrar os parâmetros de um modelo de mistura de distribuições probabilísticas que melhor descrevem os dados.\n\nO funcionamento básico do algoritmo Expectation-Maximization é o seguinte:\n\n1. Inicializa os parâmetros do modelo de mistura de forma aleatória ou usando alguma heurística.\n2. Passo de Expectation (E-step): Calcula a probabilidade de cada ponto de dados pertencer a cada componente da mistura (responsabilidades).\n3. Passo de Maximization (M-step): Atualiza os parâmetros do modelo para maximizar a probabilidade conjunta dos dados e das 4. responsabilidades calculadas no passo anterior.\n4. Repete os passos 2 e 3 até que os parâmetros converjam ou até que um critério de parada seja atingido.\n\nAlém do spherical, os outros tipos de covariância são:\n\n1. 'tied': Neste caso, todas as componentes do modelo compartilham a mesma matriz de covariância, que é uma matriz completa e simétrica. Isso significa que todas as variáveis têm a mesma covariância entre si.\n\n2. 'diag': Neste caso, cada componente tem sua própria matriz diagonal de covariância, o que significa que as variáveis são consideradas independentes umas das outras, exceto pela sua variância. Ou seja, a covariância entre diferentes dimensões é zero.\n\n3. 'full': Neste caso, cada componente do modelo tem sua própria matriz completa e simétrica de covariância. Isso significa que não há restrições nas covariâncias entre as diferentes variáveis, permitindo correlações arbitrárias entre elas.\n\nEm alguns casos, a escolha deles podem afetar significativamente o agrupamento dos dados.\n\n## Agrupamento Hierarquico Aglomerativo\n\nO Agrupamento Hierárquico Aglomerativo é um algoritmo de agrupamento hierárquico que constrói uma árvore de clusters. Ele começa com cada ponto de dados como um cluster separado e, em seguida, mescla os clusters mais próximos com base em uma métrica de distância até restar apenas um cluster.\n\nA ideia básica do algoritmo é a seguinte:\n\n1. Comece com cada ponto de dados como um cluster separado.\n2. Mescle os dois clusters mais próximos em um único cluster.\n4. Atualize a matriz de distância para refletir as novas distâncias entre clusters.\n5. Repita os passos 2 e 3 até que reste apenas um cluster.\n\nO Agrupamento Hierárquico Aglomerativo é útil para explorar relacionamentos hierárquicos nos dados e pode ser visualizado como um dendrograma, que mostra como os clusters são mesclados em cada etapa.\n\nO parâmetro linkage no algoritmo de Agrupamento Hierárquico Aglomerativo define a estratégia utilizada para calcular a distância entre os clusters durante a mesclagem. Existem diferentes métodos de ligação (linkage) disponíveis:\n\n1. 'complete': Calcula a distância máxima entre os pontos de dois clusters. A distância entre dois clusters é a distância máxima entre seus pontos.\n\n2. 'single': Calcula a distância mínima entre os pontos de dois clusters. A distância entre dois clusters é a distância mínima entre seus pontos.\n\n4. 'average': Calcula a média das distâncias entre os pontos de dois clusters. A distância entre dois clusters é a média das distâncias entre seus pontos.\n\n5. 'ward': Minimiza a variância dos clusters sendo mesclados. Essa abordagem tende a formar clusters de tamanhos relativamente iguais.\n\n## Agrupamento DBSCAN\n\nO DBSCAN (Density-Based Spatial Clustering of Applications with Noise) é um algoritmo de agrupamento baseado em densidade que é capaz de identificar clusters de formatos e tamanhos arbitrários em um conjunto de dados. Ele é especialmente útil quando os clusters têm densidades diferentes, pois ele define clusters como regiões de alta densidade separadas por regiões de baixa densidade.\n\nO funcionamento básico do algoritmo DBSCAN é o seguinte:\n\n1. Cada ponto de dados é classificado como um ponto central, um ponto de borda ou um ponto de ruído.\n2. Para cada ponto central, o algoritmo forma um cluster ao seu redor, incluindo todos os pontos alcançáveis por densidade a partir desse ponto.\n3. Pontos de borda são aqueles que estão dentro da vizinhança de densidade de um ponto central, mas não são pontos centrais eles próprios. Eles são atribuídos ao cluster do ponto central mais próximo em sua vizinhança.\n4. Pontos de ruído são aqueles que não são pontos centrais nem pontos de borda e são descartados ou considerados outliers.\n\nO DBSCAN é útil para encontrar clusters em conjuntos de dados onde os clusters têm diferentes densidades ou quando há presença de ruído nos dados. Ele não requer a especificação do número de clusters a priori, o que o torna uma escolha popular para muitos problemas de agrupamento. Além disso, o DBSCAN é capaz de lidar com clusters de forma arbitrária, não se limitando a formas geométricas específicas.\n\n## Considerações Finais\n\nComo pode ser visto nos gráficos 2D e 3D, após o agrupamento, os dados tendem a se concentrar em volta dos centróides que são dois, visto que correspondem ao número de clusters especificado.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"agrupamento_de_dados.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.40","theme":"darkly","title":"Agrupamento de dados"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}