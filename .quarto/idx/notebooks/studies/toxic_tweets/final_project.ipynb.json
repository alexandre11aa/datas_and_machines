{"title":"Projeto Final","markdown":{"yaml":{"title":"Projeto Final"},"headingText":"Resumo do Conjunto de Dados","containsRefs":false,"markdown":"\n\n\n\n\nProfessor: Elias Jacob\n\nAluno: Alexandre Estrela de L. Nobrega\n\nConjunto de Dados: ToLD-Br\n\n---\n\n\nToLD-Br é o maior conjunto de dados para tweets tóxicos em português brasileiro, desenvolvido a partir de 42 anotadores selecionados a partir de um grupo de 129 voluntários. Os anotadores foram selecionados visando criar um grupo plural em termos de demografia (etnia, orientação sexual, idade, gênero). Cada tweet foi rotulado por três anotadores em 6 categorias possíveis: LGBTQ+fobia, Xenofobia, Obsceno, Insulto, Misoginia e Racismo.\n\nDado os rótulos, foi possível definir um dataset com texto do tweet (string) seguido por uma classe binária “tóxica” com valores 0 ou 1. O valor de 0 representa um texto não tóxico, e 1 representa um comportamento tóxico.\n\n---\n\n[Baixar dados.](https://github.com/JAugusto97/ToLD-Br/blob/main/experiments/data/1annotator.zip)\n\n[Fonte dos dados.](https://huggingface.co/datasets/told-br) \n\n\n\n#### Configurando Dados\n\n#### Função de Limpeza de Dados\n\n#### Análise de Palavras mais Citadas\n\nÉ sempre bom ter uma noção das palavras que mais aparecem nas frases dos usuários, para assim receber possíveis direcionamentos na criação das funções de rotulagem.\n\n#### Separando DataFrame entre Treino, Teste e Desenvolvimento\n\n#### Labeling Functions (Funções de Rotulagem | LF) para Palavras\n\nAs funções de rotulagem de palavras para o presente dataset, servirão para definir com base nas palavras da frase do usuário, se seu comentário foi tóxico ou não.\n\n- **( 1 ) Tóxico**: Quando alguma palavra ofensiva e/ou tóxica está presente na frase.\n\n- **( 0 ) Não tóxico**: Quando alguma palavra de elogio e/ou gentil está presente na frase.\n\n- **( -1 ) Abstenção**: Quando as palavras tóxicas ou não tóxicas não estiverem presentes na frase.\n\nNota-se que a esmagadora maioria das das palavras definidas nas LF's não estão presentes no gráfico da nuvem de palavras. Porém é importante ter em mente que a escolha das palavras que irão compor elas não está unicamente associada a quantidade de vezes que elas aparecem nos textos, pois também é relevante escolher palavras com alto grau de certeza de que caso elas componham a frase, será obtido um rótulo correto.\n\n##### Analisando Influência das Funções de Rotulagem\n\n1. **j**: Índice da função de rotulagem\n\n2. **Polarity**: Se a LF se refere a tóxidade e/ou não tóxidade.\n\n3. **Coverage**: Proporção de vezes que uma função de rotulagem forneceu rotulos para instâncias (amostras de dados).\n\n4. **Overlaps**: Proporção de vezes que uma função de rotulagem forneceu rótulos para instâncias que foram rotuladas por pelo menos outra função de rotulagem de mesma polaridade.\n\n5. **Conflicts**: Proporção de vezes que uma função de rotulagem atribuiu rótulos de polaridade diferente dos rótulos atribuídos por outras funções de rotulagem para as mesmas instâncias.\n\nA tabela mostra que as LF's conseguiram cobrir aproximadamente 54% de todo o dataset, com algumas palavras que estiveram presentes na nuvem de palavras (porra e cu) ganhando destaque por seu alto *Coverage*, e baixo *Conflict*.\n\n##### Analisando o Acerto das Funções de Rotulagem\n\nComo pode ser visto na tabela, todas as funções de rotulagem obtiveram um grau de acertabilidade, ao comparar com os rótulos originais, igual ou maior que 50% (com a esmagadora maioria sendo maior).\n\n##### Analisando Conflito entre Funções de Rotulagem\n\nO gráfico da matriz de conflito demonstra que de forma geral é bem baixo o índice de conflitos, com apenas alguns pontos apresentando uma maior diferença do padrão.\n\n#### Labeling Functions para Palavras com uso de Transformer\n\nO uso de um transformer como LF, será a aplicação de um modelo pré-treinado (a partir de um dataset com características semelhantes) para a rotulação das instâncias. O autor do transformer utilizado no presente carderno o define como um classificador de sequência de modelo multilíngue Distil-Bert treinado com base no conjunto de dados JIGSAW Toxic Comment Classification Challenge.\n\n---\n\nO autor do transformer explica que o modelo foi treinado em um subconjunto aleatório do conjunto de dados told-br (1/3 do tamanho original). Ele deixa claro que o principal objetivo é fornecer um pequeno modelo que possa ser usado para classificar tweets em português brasileiro de forma binária ('tóxico' ou 'não tóxico').\n\nO conjunto de dados que o transformer utilizou curiosamente foi o mesmo que está sendo usado no presente estudo. Será interessante ver como ele desempenhará apenas compondo parte das funções de rotulagem.\n\n---\n\n[Fonte do modelo do Transformer.](https://huggingface.co/inctdd/told_br_binary_sm)\n\nCriando Labeling Function para Transformer\n\nAplicando as Funções de Rotulagem antigas com a nova do Transformer\n\nO transformer aumentou a cobertura de rotulação das instâncias de aproximadamente 54% para 86%, um aumento significativo de aproximadamente 32%. Porém, é importante perceber que o transformer atingiu um alto índice de conflito.\n\nAnalisando a nova Matriz de Conflito\n\nO índice de acertabilidade do transformer como visto na tabela foi extremamente alto, contudo, mesmo assim apresentou erros, e liderou o conflito com as outras funções de rotulagem, principalmente com a palavra *cu* que é a mais citada das palavras escolhidas para compor as LF's.\n\n#### Labeling Functions de Modelo Treinado a partir de dados rotulados por as LF's das Palavras e do Transformer\n\n- A lógica que se segue é treinar um modelo de aprendizado de máquinas a partir das LF's criadas anteriormente, e criar uma LF com ele.\n\nDefinindo Função para treinamento de diferentes modelos\n\nDesempenho de diferentes modelos treinados a partir de Funções de Rotulagens que misturam a identificação de palavras com o Transformer\n\nDesempenho de diferentes modelos treinados a partir de apenas o Transformer\n\nOs modelos treinados apenas pelo transformer obtiveram melhor desempenho do que os treinados com as funções de rotulagem que uniram a identificação de palavras mais o transformer. Contudo, por mais que tenha tido um desempenho inferior, para o bem do trabalho continuaremos usando as funções de rotulagem, para gerar um resultado com a partir de formas mais variadas de rotulação.\n\nCriando Função de Rotulagem para melhor modelo obtido a partir do treinamento dos diversos modelos para o DataFrame de desenvolvimento\n\nO modelo treinado aumentou a cobertura de rotulagem de aproximadamente 86% para 88%. Não é um aumentou substancial, porém se mostrou útil.\n\n    Recapitulando conceitos a partir de modelo de rotulagem final (Palavras + Transformer + Modelo de Aprendizado de Máquinas) obtido:\n\n1. Cobertura das Funções de Rotulagem:\n\n    - As funções de rotulagem podem cobrir diferentes partes do conjunto de dados, ou seja, algumas funções podem rotular mais exemplos que outras. Isso é o que significa \"cobertura\".\n\n2. Sobreposição e Conflito:\n\n    - As funções de rotulagem podem se sobrepor, o que significa que mais de uma função pode rotular o mesmo exemplo.\nElas também podem entrar em conflito, o que significa que diferentes funções podem atribuir rótulos diferentes ao mesmo exemplo.\n\n3. Precisões:\n\n    - Cada função de rotulagem pode ter uma precisão diferente, ou seja, algumas podem ser mais precisas na atribuição de rótulos corretos do que outras.\n\n4. Histograma:\n\n    - Para entender melhor a cobertura total das funções de rotulagem, podemos visualizar um histograma que mostra quantos rótulos foram atribuídos pelos LFs aos pontos de dados no conjunto de treinamento.\n    - Esse histograma ajuda a dar uma ideia de quantos exemplos foram rotulados por nenhuma, uma ou várias funções de rotulagem, o que é essencial para avaliar a qualidade e a cobertura do processo de rotulagem automática.\n\nO gráfico mostra que a maioria das instâncias foram rotuladas por entre uma e duas funções de rotulagem. Isso se deve ao Transformer aliado ao modelo de AM que possuíram altos Overlaps, cobrindo assim as funções de rotulagens das palavras.\n\n#### Comparando treinamento modelo de AM para DataFrame com Rótulos Reais, e Rótulos de Funções de Rotulagem\n\n    OBS: RETIRANDO ABSTENÇÕES DO DF COM RÓTULOS ORIGINAIS E GERADOS\n\nAtribuindo Rótulos obtidos a partir de Funções das Rotulagem no DataFrame para Treino Final\n\nComo pode ser visto, os rótulos gerados a partir das LFs previstos com sucesso (diferentes de -1) obtiveram uma acurácia de **78.26%** comparando diretamente com rotulos reais.\n\nApenas para fins de verificação de qual modelo treinado (o com rotulagens reais e o com rotulagens geradas) do DataFrame de treino melhor irá predizer dados novos, que serão os ainda intocados do DataFrame de teste. Para isso será utilizado o modelo de treinamento já usado anteriormente (LSVC). Ele foi escolhido visando diminuir o custo computacional do teste, dado as limitações da máquina utilizada.\n\nPor incrível que pareça, o dataframe com **rótulos gerados** desempenhou melhor que o com **rótulos originais** na predição do DataFrame de teste. É um resultado curioso, e um pouco assustador. Porém, é importante notar que as linhas com textos com os resultados inconclusivos (-1) para os **rótulos gerados**, foram retirados tanto deles como dos **rótulos originais**. Se faz necessário verificar se caso eles estivessem no treinamento do dataframe dos **rótulos originais**, ele acabaria gerando predições melhores que a dos **rótulos gerados** por causa da maior cobertura de casos.\n\n#### Comparando treinamento modelo de AM para DataFrame com Rótulos Reais, e Rótulos de Funções de Rotulagem\n\n\n    OBS: RETIRANDO ABSTENÇÕES APENAS DO DF COM GERADOS\n\nNovamente os rótulos originais obtiveram uma acurácia menor que a dos rótulos gerados. É curioso, mas essas são algumas possíveis explicações analisadas. \n\n- **DataFrame de Teste**: O DataFrame de teste foi um recorte do dataset não usado durante todo o aprendizado de máquinas, porém, pode ser que esse recorte em particular seja melhor representado pelo modelo treinado com o DF com rótulos gerados, do que pelo modelo treinado com o DF com rótulos originais.\n\n- **Exclusão de Dados Ambiguos**: Ao extrair os comentários que as LFs não conseguiram rotular, retira-se com isso comentários que podem ser contraditórios para a máquina. Isso pode ser constatado ao notar que o DF com rótulos originais que tiveram as abstenções das LFs excluídas geraram um modelo melhor do que  o DF que não excluiu. Aliado a outros fatores, isso pode ter agravado o motivo que levou a uma menor acurácia.\n\n- **Influência do Transformer**: Por mais que o transformer tenha apenas integrado parte das LF's que realizaram a rotulagem, ele se trata de um modelo para o mesmo dataset do trabalho, logo, a influência dele junto de outros fatores pode ter sido preponderante para que o DataFrame com rótulos gerados tenha gerado predições melhores que o DataFrame com rótulos originais.\n\n- **Modelo de Aprendizado de Máquinas**: A primeira é que como o modelo treinado foi o mesmo usado para os dois, sem ajustes de acordo com cada um dos DF's, talvez ele por acaso seja mais ajustado ao DF dos rótulos gerados, contudo, caso fosse ajustado um modelo para cada um dos dois DF's, visando elevar de forma particular para cada suas respectivas acurácias, os rótulos originais obtivessem resultados melhores que os rótulos gerados.\n\n- **Particularidades do Dataset**: O dataset usado visando extrair comentários tóxicos dos usuários do twitter por si só é rotulado de forma subjetiva. Isto porque comentários que usam palavras de baixo calão não necessariamente são tóxicos, e a interpretação pode variar bastante dependendo de quem o analisa. Logo, pode ser que os rótulos atribuídos pelas LB's demonstrem menos subjetividade, e por mais que os dados usados para testar a acurácia possua rótulos originais não usados no treinamento, de alguma forma essa diminuição da subjetividade tenha ajudado no treinamento do modelo de AM.\n\n- **Tamanho do Dataset**: O tamanho do dataset também pode ter sido um fator preponderante. Isto por que talvez a quantidade de dados usados no treinamento tenham limitado mais a capacidade de predição do DF com rótulos originais, do que a do DF com rótulos gerados.\n\nDe qualquer forma, para este caso, com este Dataset, os rótulos gerados para o Dataset se mostrou mais eficaz que os rótulos originais no treinamento de modelos de aprendizado de máquinas.\n","srcMarkdownNoYaml":"\n\n\n\n\nProfessor: Elias Jacob\n\nAluno: Alexandre Estrela de L. Nobrega\n\nConjunto de Dados: ToLD-Br\n\n---\n\n#### Resumo do Conjunto de Dados\n\nToLD-Br é o maior conjunto de dados para tweets tóxicos em português brasileiro, desenvolvido a partir de 42 anotadores selecionados a partir de um grupo de 129 voluntários. Os anotadores foram selecionados visando criar um grupo plural em termos de demografia (etnia, orientação sexual, idade, gênero). Cada tweet foi rotulado por três anotadores em 6 categorias possíveis: LGBTQ+fobia, Xenofobia, Obsceno, Insulto, Misoginia e Racismo.\n\nDado os rótulos, foi possível definir um dataset com texto do tweet (string) seguido por uma classe binária “tóxica” com valores 0 ou 1. O valor de 0 representa um texto não tóxico, e 1 representa um comportamento tóxico.\n\n---\n\n[Baixar dados.](https://github.com/JAugusto97/ToLD-Br/blob/main/experiments/data/1annotator.zip)\n\n[Fonte dos dados.](https://huggingface.co/datasets/told-br) \n\n\n\n#### Configurando Dados\n\n#### Função de Limpeza de Dados\n\n#### Análise de Palavras mais Citadas\n\nÉ sempre bom ter uma noção das palavras que mais aparecem nas frases dos usuários, para assim receber possíveis direcionamentos na criação das funções de rotulagem.\n\n#### Separando DataFrame entre Treino, Teste e Desenvolvimento\n\n#### Labeling Functions (Funções de Rotulagem | LF) para Palavras\n\nAs funções de rotulagem de palavras para o presente dataset, servirão para definir com base nas palavras da frase do usuário, se seu comentário foi tóxico ou não.\n\n- **( 1 ) Tóxico**: Quando alguma palavra ofensiva e/ou tóxica está presente na frase.\n\n- **( 0 ) Não tóxico**: Quando alguma palavra de elogio e/ou gentil está presente na frase.\n\n- **( -1 ) Abstenção**: Quando as palavras tóxicas ou não tóxicas não estiverem presentes na frase.\n\nNota-se que a esmagadora maioria das das palavras definidas nas LF's não estão presentes no gráfico da nuvem de palavras. Porém é importante ter em mente que a escolha das palavras que irão compor elas não está unicamente associada a quantidade de vezes que elas aparecem nos textos, pois também é relevante escolher palavras com alto grau de certeza de que caso elas componham a frase, será obtido um rótulo correto.\n\n##### Analisando Influência das Funções de Rotulagem\n\n1. **j**: Índice da função de rotulagem\n\n2. **Polarity**: Se a LF se refere a tóxidade e/ou não tóxidade.\n\n3. **Coverage**: Proporção de vezes que uma função de rotulagem forneceu rotulos para instâncias (amostras de dados).\n\n4. **Overlaps**: Proporção de vezes que uma função de rotulagem forneceu rótulos para instâncias que foram rotuladas por pelo menos outra função de rotulagem de mesma polaridade.\n\n5. **Conflicts**: Proporção de vezes que uma função de rotulagem atribuiu rótulos de polaridade diferente dos rótulos atribuídos por outras funções de rotulagem para as mesmas instâncias.\n\nA tabela mostra que as LF's conseguiram cobrir aproximadamente 54% de todo o dataset, com algumas palavras que estiveram presentes na nuvem de palavras (porra e cu) ganhando destaque por seu alto *Coverage*, e baixo *Conflict*.\n\n##### Analisando o Acerto das Funções de Rotulagem\n\nComo pode ser visto na tabela, todas as funções de rotulagem obtiveram um grau de acertabilidade, ao comparar com os rótulos originais, igual ou maior que 50% (com a esmagadora maioria sendo maior).\n\n##### Analisando Conflito entre Funções de Rotulagem\n\nO gráfico da matriz de conflito demonstra que de forma geral é bem baixo o índice de conflitos, com apenas alguns pontos apresentando uma maior diferença do padrão.\n\n#### Labeling Functions para Palavras com uso de Transformer\n\nO uso de um transformer como LF, será a aplicação de um modelo pré-treinado (a partir de um dataset com características semelhantes) para a rotulação das instâncias. O autor do transformer utilizado no presente carderno o define como um classificador de sequência de modelo multilíngue Distil-Bert treinado com base no conjunto de dados JIGSAW Toxic Comment Classification Challenge.\n\n---\n\nO autor do transformer explica que o modelo foi treinado em um subconjunto aleatório do conjunto de dados told-br (1/3 do tamanho original). Ele deixa claro que o principal objetivo é fornecer um pequeno modelo que possa ser usado para classificar tweets em português brasileiro de forma binária ('tóxico' ou 'não tóxico').\n\nO conjunto de dados que o transformer utilizou curiosamente foi o mesmo que está sendo usado no presente estudo. Será interessante ver como ele desempenhará apenas compondo parte das funções de rotulagem.\n\n---\n\n[Fonte do modelo do Transformer.](https://huggingface.co/inctdd/told_br_binary_sm)\n\nCriando Labeling Function para Transformer\n\nAplicando as Funções de Rotulagem antigas com a nova do Transformer\n\nO transformer aumentou a cobertura de rotulação das instâncias de aproximadamente 54% para 86%, um aumento significativo de aproximadamente 32%. Porém, é importante perceber que o transformer atingiu um alto índice de conflito.\n\nAnalisando a nova Matriz de Conflito\n\nO índice de acertabilidade do transformer como visto na tabela foi extremamente alto, contudo, mesmo assim apresentou erros, e liderou o conflito com as outras funções de rotulagem, principalmente com a palavra *cu* que é a mais citada das palavras escolhidas para compor as LF's.\n\n#### Labeling Functions de Modelo Treinado a partir de dados rotulados por as LF's das Palavras e do Transformer\n\n- A lógica que se segue é treinar um modelo de aprendizado de máquinas a partir das LF's criadas anteriormente, e criar uma LF com ele.\n\nDefinindo Função para treinamento de diferentes modelos\n\nDesempenho de diferentes modelos treinados a partir de Funções de Rotulagens que misturam a identificação de palavras com o Transformer\n\nDesempenho de diferentes modelos treinados a partir de apenas o Transformer\n\nOs modelos treinados apenas pelo transformer obtiveram melhor desempenho do que os treinados com as funções de rotulagem que uniram a identificação de palavras mais o transformer. Contudo, por mais que tenha tido um desempenho inferior, para o bem do trabalho continuaremos usando as funções de rotulagem, para gerar um resultado com a partir de formas mais variadas de rotulação.\n\nCriando Função de Rotulagem para melhor modelo obtido a partir do treinamento dos diversos modelos para o DataFrame de desenvolvimento\n\nO modelo treinado aumentou a cobertura de rotulagem de aproximadamente 86% para 88%. Não é um aumentou substancial, porém se mostrou útil.\n\n    Recapitulando conceitos a partir de modelo de rotulagem final (Palavras + Transformer + Modelo de Aprendizado de Máquinas) obtido:\n\n1. Cobertura das Funções de Rotulagem:\n\n    - As funções de rotulagem podem cobrir diferentes partes do conjunto de dados, ou seja, algumas funções podem rotular mais exemplos que outras. Isso é o que significa \"cobertura\".\n\n2. Sobreposição e Conflito:\n\n    - As funções de rotulagem podem se sobrepor, o que significa que mais de uma função pode rotular o mesmo exemplo.\nElas também podem entrar em conflito, o que significa que diferentes funções podem atribuir rótulos diferentes ao mesmo exemplo.\n\n3. Precisões:\n\n    - Cada função de rotulagem pode ter uma precisão diferente, ou seja, algumas podem ser mais precisas na atribuição de rótulos corretos do que outras.\n\n4. Histograma:\n\n    - Para entender melhor a cobertura total das funções de rotulagem, podemos visualizar um histograma que mostra quantos rótulos foram atribuídos pelos LFs aos pontos de dados no conjunto de treinamento.\n    - Esse histograma ajuda a dar uma ideia de quantos exemplos foram rotulados por nenhuma, uma ou várias funções de rotulagem, o que é essencial para avaliar a qualidade e a cobertura do processo de rotulagem automática.\n\nO gráfico mostra que a maioria das instâncias foram rotuladas por entre uma e duas funções de rotulagem. Isso se deve ao Transformer aliado ao modelo de AM que possuíram altos Overlaps, cobrindo assim as funções de rotulagens das palavras.\n\n#### Comparando treinamento modelo de AM para DataFrame com Rótulos Reais, e Rótulos de Funções de Rotulagem\n\n    OBS: RETIRANDO ABSTENÇÕES DO DF COM RÓTULOS ORIGINAIS E GERADOS\n\nAtribuindo Rótulos obtidos a partir de Funções das Rotulagem no DataFrame para Treino Final\n\nComo pode ser visto, os rótulos gerados a partir das LFs previstos com sucesso (diferentes de -1) obtiveram uma acurácia de **78.26%** comparando diretamente com rotulos reais.\n\nApenas para fins de verificação de qual modelo treinado (o com rotulagens reais e o com rotulagens geradas) do DataFrame de treino melhor irá predizer dados novos, que serão os ainda intocados do DataFrame de teste. Para isso será utilizado o modelo de treinamento já usado anteriormente (LSVC). Ele foi escolhido visando diminuir o custo computacional do teste, dado as limitações da máquina utilizada.\n\nPor incrível que pareça, o dataframe com **rótulos gerados** desempenhou melhor que o com **rótulos originais** na predição do DataFrame de teste. É um resultado curioso, e um pouco assustador. Porém, é importante notar que as linhas com textos com os resultados inconclusivos (-1) para os **rótulos gerados**, foram retirados tanto deles como dos **rótulos originais**. Se faz necessário verificar se caso eles estivessem no treinamento do dataframe dos **rótulos originais**, ele acabaria gerando predições melhores que a dos **rótulos gerados** por causa da maior cobertura de casos.\n\n#### Comparando treinamento modelo de AM para DataFrame com Rótulos Reais, e Rótulos de Funções de Rotulagem\n\n\n    OBS: RETIRANDO ABSTENÇÕES APENAS DO DF COM GERADOS\n\nNovamente os rótulos originais obtiveram uma acurácia menor que a dos rótulos gerados. É curioso, mas essas são algumas possíveis explicações analisadas. \n\n- **DataFrame de Teste**: O DataFrame de teste foi um recorte do dataset não usado durante todo o aprendizado de máquinas, porém, pode ser que esse recorte em particular seja melhor representado pelo modelo treinado com o DF com rótulos gerados, do que pelo modelo treinado com o DF com rótulos originais.\n\n- **Exclusão de Dados Ambiguos**: Ao extrair os comentários que as LFs não conseguiram rotular, retira-se com isso comentários que podem ser contraditórios para a máquina. Isso pode ser constatado ao notar que o DF com rótulos originais que tiveram as abstenções das LFs excluídas geraram um modelo melhor do que  o DF que não excluiu. Aliado a outros fatores, isso pode ter agravado o motivo que levou a uma menor acurácia.\n\n- **Influência do Transformer**: Por mais que o transformer tenha apenas integrado parte das LF's que realizaram a rotulagem, ele se trata de um modelo para o mesmo dataset do trabalho, logo, a influência dele junto de outros fatores pode ter sido preponderante para que o DataFrame com rótulos gerados tenha gerado predições melhores que o DataFrame com rótulos originais.\n\n- **Modelo de Aprendizado de Máquinas**: A primeira é que como o modelo treinado foi o mesmo usado para os dois, sem ajustes de acordo com cada um dos DF's, talvez ele por acaso seja mais ajustado ao DF dos rótulos gerados, contudo, caso fosse ajustado um modelo para cada um dos dois DF's, visando elevar de forma particular para cada suas respectivas acurácias, os rótulos originais obtivessem resultados melhores que os rótulos gerados.\n\n- **Particularidades do Dataset**: O dataset usado visando extrair comentários tóxicos dos usuários do twitter por si só é rotulado de forma subjetiva. Isto porque comentários que usam palavras de baixo calão não necessariamente são tóxicos, e a interpretação pode variar bastante dependendo de quem o analisa. Logo, pode ser que os rótulos atribuídos pelas LB's demonstrem menos subjetividade, e por mais que os dados usados para testar a acurácia possua rótulos originais não usados no treinamento, de alguma forma essa diminuição da subjetividade tenha ajudado no treinamento do modelo de AM.\n\n- **Tamanho do Dataset**: O tamanho do dataset também pode ter sido um fator preponderante. Isto por que talvez a quantidade de dados usados no treinamento tenham limitado mais a capacidade de predição do DF com rótulos originais, do que a do DF com rótulos gerados.\n\nDe qualquer forma, para este caso, com este Dataset, os rótulos gerados para o Dataset se mostrou mais eficaz que os rótulos originais no treinamento de modelos de aprendizado de máquinas.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"final_project.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.40","theme":"darkly","title":"Projeto Final"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}